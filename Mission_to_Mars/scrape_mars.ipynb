{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests as req\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browser Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\":\"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_browser(browser):\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Latest Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_news():\n",
    "    try:\n",
    "        ## initialize browser and latest_news dict\n",
    "        browser = init_browser()\n",
    "        latest_news={}\n",
    "\n",
    "\n",
    "        ## define url and command browser to visit and parse HTML for posts tag   \n",
    "        nasa_url= \"https://mars.nasa.gov\"\n",
    "        news_url= \"https://mars.nasa.gov/news/\"\n",
    "        browser.visit(news_url)\n",
    "        time.sleep(1)\n",
    "    \n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        news = soup.find_all('li', class_='slide')\n",
    "\n",
    "        for new in news:\n",
    "            ## collect title, date, description and link of post\n",
    "            titles = soup.find('div', class_='content_title').text\n",
    "            date = soup.find('div', class_='list_date').text\n",
    "            description = soup.find('div', class_='article_teaser_body').text\n",
    "            link = soup.a['href']\n",
    "\n",
    "            ## add results to latest_news dictionary\n",
    "            latest_news['news_title'] = titles\n",
    "            latest_news['news_date'] = date\n",
    "            latest_news['news_about'] = description\n",
    "            latest_news[\"news_link\"] = f'{nasa_url}{link}'\n",
    "        print(\"---------------PROCESSING NEWS------------------\")\n",
    "        return latest_news\n",
    "    \n",
    "## close browser    \n",
    "    finally:        \n",
    "        close_browser(browser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Maars Spaace Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_feat_img():\n",
    "    try: \n",
    "        ##Initialize browser and empty dict; define url\n",
    "        browser = init_browser()\n",
    "        marsimages ={}\n",
    "        image_url= \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "        browser.visit(image_url)\n",
    "        time.sleep(1)\n",
    "        ##  get tags for Featured Image carousel\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        img_result = soup.find('div', class_='carousel_container')\n",
    "        print(\"------------PROCESSING FEATURED IMG---------------\")\n",
    "        \n",
    "        ## Identify and store featured image link\n",
    "        image_path = img_result.find('a', class_='button fancybox').get(\"data-fancybox-href\")\n",
    "        featured_image_url= f'https://www.jpl.nasa.gov{image_path}'\n",
    "        ## Dictionary to be inserted as a MongoDB document\n",
    "        marsimages[\"featured_img_url\"] = featured_image_url\n",
    "\n",
    "        return marsimages\n",
    "    finally:\n",
    "## close browser\n",
    "        close_browser(browser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latest Mars Weather from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_weather():\n",
    "    try:\n",
    "        ##Initialize browser and empty dict; and define URL\n",
    "        browser = init_browser()\n",
    "        latest_weather = {}\n",
    "        weather_url= \"https://twitter.com/marswxreport?lang=en\"\n",
    "        browser.visit(weather_url)\n",
    "        time.sleep(5)\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        ##define tag to parse\n",
    "        print(\"------------PROCESSING WEATHER---------------\")\n",
    "        tweet_weather = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "\n",
    "        \n",
    "        ## apend to dictionary\n",
    "        latest_weather[\"mars_weather\"] = tweet_weather\n",
    "        return latest_weather\n",
    "    \n",
    "    finally:\n",
    "        ##close browser\n",
    "        close_browser(browser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_facts():\n",
    "    mars_facts = {}\n",
    "    facts_url= \"https://space-facts.com/mars/\"\n",
    "    tables = pd.read_html(facts_url)\n",
    "    print(\"------------PROCESSING FACTS---------------\")\n",
    "    \n",
    "    ## create DF of mars facts table and convert to HTML\n",
    "    marsinfo_df = tables[0]\n",
    "    marsinfo_df.columns = [\"Mars Planet Profile\" , \"Mars Data\"]\n",
    "    marsinfo_df.set_index(\"Mars Planet Profile\", inplace=True)\n",
    "    marsfacts_html = marsinfo_df.to_html(classes = 'table table-striped')\n",
    "    marsfacts_data= marsinfo_df.to_dict()\n",
    "    mars_facts[\"mars_data_df\"] = marsfacts_data\n",
    "    \n",
    "    return mars_facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hemispheres():\n",
    "    try: \n",
    "        ##initiate browser; define URL and visit in browser\n",
    "        browser = init_browser()\n",
    "        \n",
    "        hemi_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "        head_url = \"https://astrogeology.usgs.gov\"\n",
    "        browser.visit(hemi_url)\n",
    "        time.sleep(1)\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        ## define tag and parse\n",
    "        hemispheres = soup.find_all('div', class_=\"item\")\n",
    "        print(\"------------PROCESSING HEMISPHERES-------------\")\n",
    "        \n",
    "        titles=[]\n",
    "        img_urls=[]\n",
    "        \n",
    "        for hemi in hemispheres:\n",
    "            img_title = hemi.find('h3').text\n",
    "            hemi_img_url = head_url + hemi.find('a', class_=\"itemLink product-item\")[\"href\"]\n",
    "        ## visit img url to get href for full-sized image\n",
    "            browser.visit(hemi_img_url)\n",
    "            url_to_full= browser.html\n",
    "            soup = bs(url_to_full, \"html.parser\")\n",
    "            full_img_url = head_url + soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "        ## append to list\n",
    "            titles.append(img_title)\n",
    "            img_urls.append(full_img_url)\n",
    "## add to dict\n",
    "        mars_hemispheres= dict(zip(titles, img_urls))\n",
    "\n",
    "        return mars_hemispheres\n",
    "    \n",
    "    finally:\n",
    "        ##close browser\n",
    "        close_browser(browser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Scraper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "\n",
    "    try:\n",
    "        browser = init_browser()\n",
    "        new_news = scrape_news()\n",
    "        image = scrape_feat_img()\n",
    "        weather = scrape_weather()\n",
    "        facts = scrape_facts()\n",
    "        hemis= scrape_hemispheres()\n",
    "        date = dt.datetime.now()\n",
    "        print(\"------------PROCESSING FINAL INPUT----------\")\n",
    "        data = {\n",
    "            \"news_data\": new_news,\n",
    "            \"featured_img_data\": image,\n",
    "            \"weather_data\": weather,\n",
    "            \"mars_facts\": facts,\n",
    "            \"hemispheres_data\": hemis,\n",
    "            \"last_modified\": date\n",
    "        }\n",
    "        \n",
    "        return data\n",
    "    finally:\n",
    "        close_browser(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------PROCESSING NEWS------------------\n",
      "------------PROCESSING FEATURED IMG---------------\n",
      "------------PROCESSING WEATHER---------------\n",
      "------------PROCESSING FACTS---------------\n",
      "------------PROCESSING HEMISPHERES-------------\n",
      "------------PROCESSING FINAL INPUT----------\n",
      "{'news_data': {'news_title': \"Nine Finalists Chosen in NASA's Mars 2020 Rover Naming Contest\", 'news_date': 'January 21, 2020', 'news_about': \"Nine finalists have been chosen in the essay contest for K-12 students across U.S. to name NASA's next Mars rover. Now you can help by voting for your favorite. \", 'news_link': 'https://mars.nasa.govhttp://www.nasa.gov'}, 'featured_img_data': {'featured_img_url': 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA00069_ip.jpg'}, 'weather_data': {'mars_weather': <p class=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"en\">InSight sol 411 (2020-01-22) low -96.4ºC (-141.4ºF) high -16.7ºC (1.9ºF)\n",
      "winds from the S at 5.6 m/s (12.6 mph) gusting to 22.7 m/s (50.8 mph)\n",
      "pressure at 6.30 hPa<a class=\"twitter-timeline-link u-hidden\" data-pre-embedded=\"true\" dir=\"ltr\" href=\"https://t.co/nogRqYba3I\">pic.twitter.com/nogRqYba3I</a></p>}, 'mars_facts': {'mars_data_df': {'Mars Data': {'Equatorial Diameter:': '6,792 km', 'Polar Diameter:': '6,752 km', 'Mass:': '6.39 × 10^23 kg (0.11 Earths)', 'Moons:': '2 (Phobos & Deimos)', 'Orbit Distance:': '227,943,824 km (1.38 AU)', 'Orbit Period:': '687 days (1.9 years)', 'Surface Temperature:': '-87 to -5 °C', 'First Record:': '2nd millennium BC', 'Recorded By:': 'Egyptian astronomers'}}}, 'hemispheres_data': {'Cerberus Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg', 'Schiaparelli Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg', 'Syrtis Major Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg', 'Valles Marineris Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}, 'last_modified': datetime.datetime(2020, 1, 27, 22, 22, 18, 601561)}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(scrape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
